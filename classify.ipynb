{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Droplet Classification Pipeline\n",
    "\n",
    "This notebook implements an automated pipeline for detecting and classifying droplets in microscopy images using a pre-trained XGBoost classifier.\n",
    "\n",
    "## Pipeline Overview\n",
    "1. **Quadrant Extraction**: Split multi-channel microscopy images into separate quadrants\n",
    "2. **Droplet Detection**: Load pre-computed bounding boxes for detected droplets\n",
    "3. **Feature Extraction**: Extract deep features from droplet images using MobileNetV2\n",
    "4. **Classification**: Classify droplets using pre-trained XGBoost model\n",
    "5. **Analysis**: Generate annotated images and combined spreadsheets with classification results\n",
    "\n",
    "## Input Requirements\n",
    "- Multi-channel microscopy TIF images organized in directories\n",
    "- Pre-computed droplet bounding boxes (`.pkl` files)\n",
    "- Pre-trained XGBoost classifier model\n",
    "- CSV metadata files for each experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# Data processing and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision.transforms import v2 as transforms\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Custom data processing utilities\n",
    "from src.data_processing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Functions for droplet detection, classification, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_precomputed_droplets_worker(cur_quadrant_dir, quadrant_name):\n",
    "    \"\"\"\n",
    "    Load pre-computed droplet bounding boxes and create detection visualizations.\n",
    "    \n",
    "    This function processes a single quadrant directory, loading droplet detection\n",
    "    bounding boxes from pickle files and creating annotated images showing detected droplets.\n",
    "    \n",
    "    Args:\n",
    "        cur_quadrant_dir (str): Path to the quadrant directory containing TIF images\n",
    "        quadrant_name (str): Name of the quadrant (e.g., \"488\", \"546\", \"647\")\n",
    "    \"\"\"\n",
    "    # Skip if already processed\n",
    "    if Path(f\"{cur_quadrant_dir}/droplet_detection_pkl/\").exists():\n",
    "        return\n",
    "    \n",
    "    # Extract quadrant number from directory path\n",
    "    m = re.search(\"quadrant_(\\d)\", cur_quadrant_dir)\n",
    "    if m is None:\n",
    "        raise Exception(f\"Invalid quadrant directory: {cur_quadrant_dir}\")\n",
    "\n",
    "    # Load all bounding boxes for this quadrant\n",
    "    droplets_dict = defaultdict(list)\n",
    "    for cur_dir, cur_fname in get_files_matching_regex(\n",
    "        f\"{cur_quadrant_dir}/../\",\n",
    "        f\"(?m)^\\d_([A-Z0-9]{{2}}_)?{quadrant_name}_droplet_boxes.pkl$\",\n",
    "    ):\n",
    "        # Extract TIF ID from filename\n",
    "        m = re.search(\"(?m)^(\\d)_\", cur_fname)\n",
    "        tif_id = int(m.groups()[0])\n",
    "\n",
    "        # Load bounding boxes\n",
    "        with open(f\"{cur_dir}/{cur_fname}\", \"rb\") as fp:\n",
    "            cur_bboxes = pkl.loads(fp.read())\n",
    "\n",
    "        # Process each bounding box\n",
    "        for cur_k, cur_v in cur_bboxes.items():\n",
    "            # Extract frame ID from key\n",
    "            m = re.search(f\"(?m)_(\\d+)_{quadrant_name}$\", cur_k)\n",
    "            if m is None:\n",
    "                raise Exception(\n",
    "                    f\"Key in {cur_dir}/{cur_fname} does not match: {cur_k} ({tif_id}, {quadrant_name})\"\n",
    "                )\n",
    "            frame_id = int(m.groups()[0])\n",
    "            \n",
    "            # Store droplet info (filter by aspect ratio to keep approximately circular droplets)\n",
    "            for bbox_idx, cur_bbox in enumerate(cur_v):\n",
    "                # Skip droplets with aspect ratio too far from 1 (non-circular)\n",
    "                if abs(1 - (cur_bbox[2] / cur_bbox[3])) > 0.15:\n",
    "                    continue\n",
    "                    \n",
    "                droplets_dict[(tif_id, frame_id)].append(\n",
    "                    (\n",
    "                        bbox_idx,\n",
    "                        cur_bbox[0],  # x coordinate\n",
    "                        cur_bbox[1],  # y coordinate\n",
    "                        0.25 * (cur_bbox[2] + cur_bbox[3]),  # average radius\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    # Get all TIF images in the quadrant directory\n",
    "    tifs = list(\n",
    "        sorted(get_files_matching_regex(cur_quadrant_dir, \"(?m)^\\d+_\\d+\\.tif$\"))\n",
    "    )\n",
    "\n",
    "    # Process each TIF image\n",
    "    for root, fname in tqdm(tifs, desc=f\"Processing {quadrant_name}\"):\n",
    "        # Create output directories\n",
    "        Path(f\"{cur_quadrant_dir}/droplet_detection_pkl/\").mkdir(exist_ok=True)\n",
    "        Path(f\"{cur_quadrant_dir}/droplet_detection_im/\").mkdir(exist_ok=True)\n",
    "\n",
    "        out_pkl_pth = f\"{cur_quadrant_dir}/droplet_detection_pkl/{os.path.splitext(fname)[0]}_droplets.pkl\"\n",
    "\n",
    "        # Extract indices from filename\n",
    "        m = re.search(\"(?m)^(\\d+)_(\\d+)\\.tif$\", fname)\n",
    "        ex_idx = int(m.groups()[0])\n",
    "        frame_idx = int(m.groups()[1])\n",
    "\n",
    "        # Load image\n",
    "        cur_fname = f\"{root}/{fname}\"\n",
    "        cur_im = np.array(Image.open(cur_fname))\n",
    "\n",
    "        # Get droplets for this image\n",
    "        droplets = droplets_dict[(ex_idx, frame_idx)]\n",
    "        circles = [((x, y), r) for _, x, y, r in droplets]\n",
    "\n",
    "        # Save droplet data\n",
    "        with open(out_pkl_pth, \"wb\") as fp:\n",
    "            fp.write(pkl.dumps(droplets))\n",
    "        \n",
    "        # Create visualization with circles drawn on image\n",
    "        cur_im = normalize_image(cur_im, (0.1, 99.9)).astype(np.uint8)\n",
    "        cur_im_circles = draw_circles(circles, cur_im)\n",
    "\n",
    "        Image.fromarray(cur_im_circles).save(\n",
    "            f\"{cur_quadrant_dir}/droplet_detection_im/{os.path.splitext(fname)[0]}_droplets.tif\"\n",
    "        )\n",
    "\n",
    "\n",
    "def write_droplets(quadrant_dirs, subsample):\n",
    "    \"\"\"\n",
    "    Extract and save individual droplet images for training dataset generation.\n",
    "    \n",
    "    Args:\n",
    "        quadrant_dirs (list): List of (quadrant_dir, quadrant_name) tuples\n",
    "        subsample (int): Subsampling factor (1 = save all droplets, 2 = save every 2nd, etc.)\n",
    "    \"\"\"\n",
    "    for cur_quadrant_dir, _ in quadrant_dirs:\n",
    "        print(f\"Processing {cur_quadrant_dir}\")\n",
    "        dir_hash = hex(hash(cur_quadrant_dir))[-5:]\n",
    "\n",
    "        # Skip if already processed\n",
    "        if Path(f\"{cur_quadrant_dir}/droplet_ims/\").exists():\n",
    "            continue\n",
    "        Path(f\"{cur_quadrant_dir}/droplet_ims/\").mkdir()\n",
    "\n",
    "        tifs = list(\n",
    "            sorted(get_files_matching_regex(cur_quadrant_dir, \"(?m)^\\d+_\\d+\\.tif$\"))\n",
    "        )\n",
    "\n",
    "        droplet_cnt = -1\n",
    "        for root, fname in tqdm(tifs):\n",
    "            pkl_pth = f\"{cur_quadrant_dir}/droplet_detection_pkl/{os.path.splitext(fname)[0]}_droplets.pkl\"\n",
    "\n",
    "            if not Path(pkl_pth).exists():\n",
    "                continue\n",
    "\n",
    "            # Load droplet locations\n",
    "            with open(pkl_pth, \"rb\") as fp:\n",
    "                circles = pkl.loads(fp.read())\n",
    "\n",
    "            # Load image\n",
    "            cur_fname = f\"{root}/{fname}\"\n",
    "            cur_im = np.array(Image.open(cur_fname))\n",
    "            cur_im = normalize_image(cur_im, (0.1, 99.9))\n",
    "\n",
    "            # Extract each droplet as a separate image\n",
    "            for idx, x, y, r in circles:\n",
    "                x, y, r = int(x), int(y), int(r)\n",
    "                \n",
    "                # Create circular mask\n",
    "                mask = np.zeros_like(cur_im)\n",
    "                cv2.circle(mask, (x, y), r, (1,), -1)\n",
    "                \n",
    "                # Apply mask and crop\n",
    "                crop = cv2.multiply(cur_im, mask)\n",
    "                crop = crop[y - r : y + r, x - r : x + r]\n",
    "\n",
    "                droplet_cnt += 1\n",
    "                \n",
    "                # Apply subsampling\n",
    "                if droplet_cnt % subsample != 0:\n",
    "                    continue\n",
    "                    \n",
    "                # Save droplet image\n",
    "                try:\n",
    "                    Image.fromarray(crop).save(\n",
    "                        f\"{cur_quadrant_dir}/droplet_ims/{dir_hash}_{droplet_cnt}.png\"\n",
    "                    )\n",
    "                except SystemError:\n",
    "                    pass  # Skip if image saving fails\n",
    "\n",
    "\n",
    "def classify_droplets(quadrant_dirs, classifier):\n",
    "    \"\"\"\n",
    "    Classify all detected droplets using the pre-trained XGBoost model.\n",
    "    \n",
    "    This function extracts features from droplet images using MobileNetV2 and\n",
    "    classifies them using the provided XGBoost classifier.\n",
    "    \n",
    "    Args:\n",
    "        quadrant_dirs (list): List of (quadrant_dir, quadrant_name) tuples\n",
    "        classifier (XGBWrapper): Pre-trained XGBoost classifier instance\n",
    "    \"\"\"\n",
    "    for cur_quadrant_dir, _ in quadrant_dirs:\n",
    "        # Skip if already processed\n",
    "        if Path(f\"{cur_quadrant_dir}/droplet_classification_pkl/\").exists():\n",
    "            continue\n",
    "            \n",
    "        print(f\"Working on {cur_quadrant_dir}\")\n",
    "        Path(f\"{cur_quadrant_dir}/droplet_classification_pkl/\").mkdir(exist_ok=True)\n",
    "\n",
    "        # Get all TIF images\n",
    "        tifs = list(get_files_matching_regex(cur_quadrant_dir, \"(?m)^\\d+_\\d+\\.tif$\"))\n",
    "        \n",
    "        # Collect all droplet images for batch processing\n",
    "        cur_im_droplets = []\n",
    "        droplet_indices = []\n",
    "        circles_retained = []\n",
    "        droplet_fnames = []\n",
    "        \n",
    "        for root, fname in tqdm(tifs, desc=\"Loading droplets\"):\n",
    "            pkl_pth = f\"{cur_quadrant_dir}/droplet_detection_pkl/{os.path.splitext(fname)[0]}_droplets.pkl\"\n",
    "            if not Path(pkl_pth).exists():\n",
    "                continue\n",
    "\n",
    "            # Load droplet locations\n",
    "            with open(pkl_pth, \"rb\") as fp:\n",
    "                circles = pkl.loads(fp.read())\n",
    "\n",
    "            # Load image\n",
    "            cur_fname = f\"{root}/{fname}\"\n",
    "            cur_im = np.array(Image.open(cur_fname))\n",
    "            cur_im = normalize_image(cur_im, (0.1, 99.9))\n",
    "\n",
    "            # Extract each droplet\n",
    "            for idx, x, y, r in circles:\n",
    "                x, y, r = int(x), int(y), int(r)\n",
    "                \n",
    "                # Create circular mask\n",
    "                mask = np.zeros_like(cur_im)\n",
    "                cv2.circle(mask, (x, y), r, (1,), -1)\n",
    "                \n",
    "                # Apply mask and crop\n",
    "                crop = cv2.multiply(cur_im, mask)\n",
    "                crop = crop[y - r : y + r, x - r : x + r]\n",
    "\n",
    "                # Skip droplets that intersect image borders (resulting in empty crops)\n",
    "                if 0 in crop.shape:\n",
    "                    continue\n",
    "\n",
    "                # Convert to RGB for feature extraction\n",
    "                crop = Image.fromarray(crop).convert(\"RGB\")\n",
    "                cur_im_droplets.append(crop)\n",
    "                droplet_indices.append(idx)\n",
    "                circles_retained.append((idx, x, y, r))\n",
    "                droplet_fnames.append(fname)\n",
    "\n",
    "        if len(cur_im_droplets) == 0:\n",
    "            continue\n",
    "\n",
    "        # Classify droplets in batches\n",
    "        # Larger batch size for better GPU utilization (adjust based on GPU memory)\n",
    "        bs = 500 if torch.cuda.is_available() else 100\n",
    "        length = len(cur_im_droplets)\n",
    "        pred = []\n",
    "        \n",
    "        for batch_off in tqdm(range(0, length, bs), desc=\"Classifying\"):\n",
    "            this_batch = cur_im_droplets[batch_off : batch_off + bs]\n",
    "            \n",
    "            # Extract features using MobileNetV2\n",
    "            this_batch_feats = get_features_batched(this_batch)\n",
    "\n",
    "            # Classify using XGBoost\n",
    "            this_batch_pred = classifier.predict(this_batch_feats)\n",
    "            pred.append(this_batch_pred)\n",
    "\n",
    "        # Combine predictions\n",
    "        preds = np.concatenate(pred)\n",
    "        \n",
    "        # Organize predictions by filename\n",
    "        out_dict = {xx: ([], []) for xx in set(droplet_fnames)}\n",
    "        for idx in range(length):\n",
    "            cur_fname = droplet_fnames[idx]\n",
    "            cur_droplet_idx = droplet_indices[idx]\n",
    "            cur_pred = preds[idx]\n",
    "\n",
    "            out_dict[cur_fname][0].append(cur_droplet_idx)\n",
    "            out_dict[cur_fname][1].append(cur_pred)\n",
    "\n",
    "        # Save predictions for each file\n",
    "        for cur_fname, (droplet_indices, cur_preds) in out_dict.items():\n",
    "            out_pkl_pth = f\"{cur_quadrant_dir}/droplet_classification_pkl/{os.path.splitext(cur_fname)[0]}_classified.pkl\"\n",
    "\n",
    "            with open(out_pkl_pth, \"wb\") as fp:\n",
    "                fp.write(pkl.dumps(list(zip(droplet_indices, cur_preds))))\n",
    "\n",
    "\n",
    "def create_combined_spreadsheet(quadrant_dirs):\n",
    "    \"\"\"\n",
    "    Generate combined analysis spreadsheet with classification results.\n",
    "    \n",
    "    Merges classification predictions with existing CSV metadata to create\n",
    "    a comprehensive analysis spreadsheet.\n",
    "    \n",
    "    Args:\n",
    "        quadrant_dirs (list): List of (quadrant_dir, quadrant_name) tuples\n",
    "    \"\"\"\n",
    "    for cur_quadrant_dir, _ in quadrant_dirs:\n",
    "        # Skip if already processed\n",
    "        if Path(f\"{cur_quadrant_dir}/../analysis.csv\").exists():\n",
    "            continue\n",
    "\n",
    "        # Find and load existing CSV file\n",
    "        df = None\n",
    "        for root, fname in get_files_matching_regex(\n",
    "            f\"{cur_quadrant_dir}/../\", \"(?m)^.*\\.csv$\"\n",
    "        ):\n",
    "            print(f\"Loading metadata from {root}/{fname}\")\n",
    "            df = pd.read_csv(f\"{root}/{fname}\")\n",
    "            break  # Use first CSV found\n",
    "\n",
    "        if df is None:\n",
    "            print(f\"No CSV file found for {cur_quadrant_dir}, skipping\")\n",
    "            continue\n",
    "\n",
    "        # Load all classification results\n",
    "        droplets = {}\n",
    "        tifs = list(get_files_matching_regex(cur_quadrant_dir, \"(?m)^\\d+_\\d+\\.tif$\"))\n",
    "        \n",
    "        for root, fname in tqdm(tifs, desc=\"Loading classifications\"):\n",
    "            # Parse filename\n",
    "            m = re.search(\"(?m)^(\\d+)_(\\d+)\\.tif$\", fname)\n",
    "            im_idx = int(m.groups()[0])\n",
    "            frame_idx = int(m.groups()[1])\n",
    "\n",
    "            # Load classification results\n",
    "            class_pkl_pth = f\"{cur_quadrant_dir}/droplet_classification_pkl/{os.path.splitext(fname)[0]}_classified.pkl\"\n",
    "            try:\n",
    "                with open(class_pkl_pth, \"rb\") as fp:\n",
    "                    classified = pkl.loads(fp.read())\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "                \n",
    "            # Store classifications by (tif_id, frame_id, droplet_id)\n",
    "            for droplet_id, cur_class in classified:\n",
    "                droplets[(im_idx, frame_idx, droplet_id)] = cur_class\n",
    "\n",
    "        # Add classification column to dataframe\n",
    "        df[\"class\"] = 0\n",
    "        for idx, row in df.iterrows():\n",
    "            try:\n",
    "                # Parse TIF ID (handle both numeric and string formats)\n",
    "                try:\n",
    "                    tif_id = int(row[\"tif\"])\n",
    "                except ValueError:\n",
    "                    m = re.search(\"(\\d+)_[A-Z]+\", row[\"tif\"])\n",
    "                    tif_id = int(m.groups()[0])\n",
    "                \n",
    "                # Look up classification\n",
    "                cur_class = droplets[\n",
    "                    (tif_id, int(row[\"frame\"]), int(row[\"droplet_id\"]))\n",
    "                ]\n",
    "                df.at[idx, \"class\"] = cur_class\n",
    "            except KeyError:\n",
    "                # Some droplets were skipped (e.g., intersecting image boundaries)\n",
    "                continue\n",
    "\n",
    "        # Save updated spreadsheet\n",
    "        output_path = f\"{cur_quadrant_dir}/../analysis.csv\"\n",
    "        df.to_csv(output_path, sep=\",\", index=False)\n",
    "        print(f\"Saved analysis to {output_path}\")\n",
    "\n",
    "\n",
    "def write_droplet_debug_ims(quadrant_dir):\n",
    "    \"\"\"\n",
    "    Create annotated images showing classified droplets with labels.\n",
    "    \n",
    "    Generates visualization images with droplets circled and labeled with their\n",
    "    classification results for visual verification.\n",
    "    \n",
    "    Args:\n",
    "        quadrant_dir (str): Path to the quadrant directory\n",
    "    \"\"\"\n",
    "    # Skip if already processed\n",
    "    if Path(f\"{quadrant_dir}/droplet_classification_im/\").exists():\n",
    "        return\n",
    "    Path(f\"{quadrant_dir}/droplet_classification_im/\").mkdir(exist_ok=True)\n",
    "\n",
    "    tifs = list(sorted(get_files_matching_regex(quadrant_dir, \"(?m)^\\d+_\\d+\\.tif$\")))\n",
    "    \n",
    "    for root, fname in tqdm(tifs, desc=\"Creating debug images\"):\n",
    "        detection_pkl_pth = f\"{quadrant_dir}/droplet_detection_pkl/{os.path.splitext(fname)[0]}_droplets.pkl\"\n",
    "        classification_pkl_pth = f\"{quadrant_dir}/droplet_classification_pkl/{os.path.splitext(fname)[0]}_classified.pkl\"\n",
    "\n",
    "        # Load detection and classification results\n",
    "        with open(detection_pkl_pth, \"rb\") as fp:\n",
    "            dets = pkl.loads(fp.read())\n",
    "        \n",
    "        try:\n",
    "            with open(classification_pkl_pth, \"rb\") as fp:\n",
    "                classes = pkl.loads(fp.read())\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "\n",
    "        # Load image\n",
    "        cur_fname = f\"{root}/{fname}\"\n",
    "        cur_im = np.array(Image.open(cur_fname))\n",
    "\n",
    "        # Match detections with classifications\n",
    "        classes = {idx: cls for idx, cls in classes}\n",
    "        retained_dets = []\n",
    "        retained_cls = []\n",
    "        \n",
    "        for cur in dets:\n",
    "            if cur[0] in classes:\n",
    "                retained_dets.append(cur)\n",
    "                retained_cls.append((cur[0], classes[cur[0]]))\n",
    "\n",
    "        # Draw circles with labels\n",
    "        cur_im = normalize_image(cur_im, (0.1, 99.9)).astype(np.uint8)\n",
    "        cur_im_circles = draw_circles(\n",
    "            [((x, y), r) for _, x, y, r in retained_dets],\n",
    "            cur_im,\n",
    "            labels=[f\"{yy[0:3]} ({xx})\" for xx, yy in retained_cls],  # Label: \"Class (ID)\"\n",
    "        )\n",
    "        \n",
    "        # Save annotated image\n",
    "        Image.fromarray(cur_im_circles).save(\n",
    "            f\"{quadrant_dir}/droplet_classification_im/{os.path.splitext(fname)[0]}_classification.tif\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Global model cache to avoid reloading\n",
    "_FEATURE_EXTRACTOR_MODEL = None\n",
    "_FEATURE_EXTRACTOR_DEVICE = None\n",
    "\n",
    "def get_feature_extractor_model():\n",
    "    \"\"\"\n",
    "    Get or create the cached feature extraction model.\n",
    "    This avoids reloading the model for every batch, providing significant speedup.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (model, device)\n",
    "    \"\"\"\n",
    "    global _FEATURE_EXTRACTOR_MODEL, _FEATURE_EXTRACTOR_DEVICE\n",
    "    \n",
    "    if _FEATURE_EXTRACTOR_MODEL is None:\n",
    "        print(\"Loading MobileNetV2 feature extractor (one-time initialization)...\")\n",
    "        _FEATURE_EXTRACTOR_DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        _FEATURE_EXTRACTOR_MODEL = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT).to(_FEATURE_EXTRACTOR_DEVICE)\n",
    "        _FEATURE_EXTRACTOR_MODEL.eval()\n",
    "        \n",
    "        # Remove classification layer to extract features from penultimate layer\n",
    "        _FEATURE_EXTRACTOR_MODEL.classifier[1] = torch.nn.Identity()\n",
    "        \n",
    "        print(f\"Model loaded on device: {_FEATURE_EXTRACTOR_DEVICE}\")\n",
    "    \n",
    "    return _FEATURE_EXTRACTOR_MODEL, _FEATURE_EXTRACTOR_DEVICE\n",
    "\n",
    "\n",
    "def extract_features(image, is_batch=False):\n",
    "    \"\"\"\n",
    "    Extract deep features from images using MobileNetV2 pre-trained on ImageNet.\n",
    "    Uses a cached model for improved performance.\n",
    "    \n",
    "    Args:\n",
    "        image (torch.Tensor): Input image tensor(s)\n",
    "        is_batch (bool): Whether input is a batch of images. Defaults to False.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Extracted feature vectors (1280-dimensional for MobileNetV2)\n",
    "    \"\"\"\n",
    "    # Get cached model\n",
    "    model, device = get_feature_extractor_model()\n",
    "    \n",
    "    # Add batch dimension if single image\n",
    "    if is_batch:\n",
    "        batch_img_tensor = image\n",
    "    else:\n",
    "        batch_img_tensor = image.unsqueeze(0)\n",
    "\n",
    "    # Move to GPU if available\n",
    "    batch_img_tensor = batch_img_tensor.to(device)\n",
    "\n",
    "    # Extract features without gradient computation\n",
    "    with torch.no_grad():\n",
    "        features = model(batch_img_tensor)\n",
    "\n",
    "    # Flatten and convert to numpy\n",
    "    if is_batch:\n",
    "        features_flattened = torch.flatten(features, start_dim=1).detach().cpu().numpy()\n",
    "    else:\n",
    "        features_flattened = torch.flatten(features, start_dim=1).detach().cpu().numpy()[0]\n",
    "\n",
    "    return features_flattened\n",
    "\n",
    "\n",
    "def get_features_batched(images, adjust_size=True):\n",
    "    \"\"\"\n",
    "    Extract features from a batch of images efficiently.\n",
    "    \n",
    "    Args:\n",
    "        images (list): List of PIL Images\n",
    "        adjust_size (bool): Whether to apply preprocessing transforms. Defaults to True.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Feature matrix of shape (n_images, 1280)\n",
    "    \"\"\"\n",
    "    # Define standard ImageNet preprocessing\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToImage(),\n",
    "        transforms.ToDtype(torch.float32, scale=True),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Apply preprocessing if needed\n",
    "    if adjust_size:\n",
    "        images = [preprocess(img) for img in images]\n",
    "\n",
    "    # Stack into batch and extract features\n",
    "    batch = torch.stack(images)\n",
    "    features = extract_features(batch, is_batch=True)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "class XGBWrapper:\n",
    "    \"\"\"\n",
    "    Wrapper class for XGBoost to handle multi-class classification with label encoding.\n",
    "    This class is required to unpickle the pre-trained model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, params, epochs):\n",
    "        \"\"\"\n",
    "        Initialize XGBoost wrapper.\n",
    "        \n",
    "        Args:\n",
    "            params (dict): XGBoost parameters (max_depth, eta, objective, etc.)\n",
    "            epochs (int): Number of boosting rounds\n",
    "        \"\"\"\n",
    "        self.params = params\n",
    "        self.epochs = epochs\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train XGBoost model on feature matrix X with labels y.\n",
    "        \n",
    "        Args:\n",
    "            X (numpy.ndarray): Feature matrix\n",
    "            y (array-like): Class labels (strings)\n",
    "        \"\"\"\n",
    "        # Encode string labels to integers\n",
    "        labels = self.label_encoder.fit_transform(y)\n",
    "        self.params[\"num_class\"] = len(self.label_encoder.classes_)\n",
    "        dtrain = xgb.DMatrix(X, label=labels)\n",
    "\n",
    "        # Train the model\n",
    "        self.model = xgb.train(self.params, dtrain, self.epochs)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels for feature matrix X.\n",
    "        \n",
    "        Args:\n",
    "            X (numpy.ndarray): Feature matrix\n",
    "            \n",
    "        Returns:\n",
    "            numpy.ndarray: Predicted class labels (strings)\n",
    "        \"\"\"\n",
    "        dtest = xgb.DMatrix(X)\n",
    "        y_pred = self.model.predict(dtest)\n",
    "        y_pred = y_pred.argmax(axis=1)\n",
    "        y_pred = self.label_encoder.inverse_transform(y_pred)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Pipeline Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/klavs/Desktop/PhD/Tanu/image-thresholding/data/Corrected_exp1_50uMg3bp1pro_1.5mgml_lysg156e\"\n",
    "skip_droplet_classification = False  # Set to True to skip classification step\n",
    "write_raw_droplets = False  # Set to True to export raw droplet images for training data\n",
    "skip_debug_ims = False  # Set to True to skip creating annotated debug images\n",
    "skip_combined_spreadsheet = False  # Set to True to skip generating analysis CSV\n",
    "\n",
    "trained_n = 100000  # Number of samples used to train the classifier\n",
    "feature = f\"mobilenetv2_max{trained_n}\"\n",
    "classifier = \"xgb\"\n",
    "\n",
    "# =============================================================================\n",
    "# Quadrant Configuration\n",
    "# =============================================================================\n",
    "# Map experiment conditions to (classification_wavelength, reference_wavelength)\n",
    "# Classification wavelength: channel containing droplets to classify\n",
    "# Reference wavelength: channel used for droplet detection\n",
    "classify_quadrant = {\n",
    "    \"G3BP1_2/P525L\": (488, 647),  # Classify 546nm channel, detect in 647nm\n",
    "}\n",
    "\n",
    "# Quadrant position mapping (4-quadrant layout)\n",
    "# Layout:\n",
    "#   0  1\n",
    "#   2  3\n",
    "quadrant_map = {\n",
    "    488: 3,  # Bottom right\n",
    "    546: 2,  # Bottom left\n",
    "    647: 1,  # Top right (reference channel)\n",
    "}\n",
    "\n",
    "# Quadrant names for file identification\n",
    "quadrant_names = {\n",
    "    1: \"647\",\n",
    "    2: \"546\",\n",
    "    3: \"488\",\n",
    "}\n",
    "\n",
    "# Convert wavelength pairs to quadrant indices\n",
    "classify_quadrant = {\n",
    "    experiment: (quadrant_map[classify_channel], quadrant_map[detect_channel])\n",
    "    for experiment, (classify_channel, detect_channel) in classify_quadrant.items()\n",
    "}\n",
    "\n",
    "print(f\"Quadrant configuration: {classify_quadrant}\")\n",
    "print(\"\\nLoading classifier...\")\n",
    "classifier_path = f\"{os.path.join(dataset_path, classifier+'_trained_'+feature)}.pkl\"\n",
    "print(f\"Using classifier from: {classifier_path}\")\n",
    "\n",
    "with open(classifier_path, \"rb\") as fp:\n",
    "    clf = pkl.loads(fp.read())\n",
    "\n",
    "print(f\"Classifier loaded successfully\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: Extracting quadrant images from multi-channel TIFs\")\n",
    "print(\"=\"*80)\n",
    "quadrant_dirs = list(extract_quadrants(dataset_path, classify_quadrant))\n",
    "quadrant_dirs = [(xx, quadrant_names[yy]) for xx, yy in quadrant_dirs]\n",
    "print(f\"Found {len(quadrant_dirs)} quadrant directories to process\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: Reading pre-computed droplet bounding boxes\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Process sequentially (multiprocessing doesn't work well in Jupyter notebooks)\n",
    "for quadrant_dir, quadrant_name in tqdm(quadrant_dirs, desc=\"Processing quadrants\"):\n",
    "    _get_precomputed_droplets_worker(quadrant_dir, quadrant_name)\n",
    "\n",
    "print(\"Droplet detection loading complete\")\n",
    "\n",
    "if write_raw_droplets:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STEP 3: Writing raw droplet images for training data generation\")\n",
    "    print(\"=\"*80)\n",
    "    write_droplets(quadrant_dirs, subsample=1)\n",
    "else:\n",
    "    print(\"\\nSkipping raw droplet export (write_raw_droplets=False)\")\n",
    "\n",
    "if skip_droplet_classification:\n",
    "    print(\"\\nSkipping droplet classification (skip_droplet_classification=True)\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STEP 4: Classifying droplets using XGBoost\")\n",
    "    print(\"=\"*80)\n",
    "    classify_droplets(quadrant_dirs, clf)\n",
    "    print(\"Classification complete\")\n",
    "\n",
    "if skip_debug_ims:\n",
    "    print(\"\\nSkipping debug image generation (skip_debug_ims=True)\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STEP 5: Creating annotated images with classification labels\")\n",
    "    print(\"=\"*80)\n",
    "    # Process sequentially (multiprocessing doesn't work well in Jupyter notebooks)\n",
    "    for quadrant_dir, _ in tqdm(quadrant_dirs, desc=\"Creating debug images\"):\n",
    "        write_droplet_debug_ims(quadrant_dir)\n",
    "    print(\"Debug images created\")\n",
    "\n",
    "if skip_combined_spreadsheet:\n",
    "    print(\"\\nSkipping spreadsheet generation (skip_combined_spreadsheet=True)\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STEP 6: Creating combined analysis spreadsheet\")\n",
    "    print(\"=\"*80)\n",
    "    create_combined_spreadsheet(quadrant_dirs)\n",
    "    print(\"Analysis spreadsheet generated\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PIPELINE COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "droplet_classification_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
