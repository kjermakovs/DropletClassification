{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd784f0e",
   "metadata": {},
   "source": [
    "# Image Thresholding for Condensate Detection\n",
    "\n",
    "This notebook implements automated thresholding techniques to segment and extract biomolecular condensates from microscopy images.\n",
    "\n",
    "## Pipeline Overview\n",
    "1. **Image Loading**: Load images from categorized directories (Homogenous, Aggregate, Condensate)\n",
    "2. **Histogram Analysis**: Analyze pixel intensity distributions\n",
    "3. **Threshold Detection**: Apply KDE method to find optimal thresholds\n",
    "4. **Binary Segmentation**: Convert images to binary masks\n",
    "5. **Morphological Processing**: Apply erosion+dilation to remove noise while preserving features\n",
    "6. **Batch Processing**: Process and save all images with optimal threshold\n",
    "\n",
    "## Method: KDE (Kernel Density Estimation)\n",
    "Uses statistical analysis to detect histogram tail inflection points, identifying the transition from signal to background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d564136",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2204ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy import signal\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d07ae3",
   "metadata": {},
   "source": [
    "## Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1efd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_with_metadata(root_path):\n",
    "    \"\"\"\n",
    "    Load images from specified subfolders and store them with metadata.\n",
    "    \n",
    "    Expected directory structure:\n",
    "        root_path/\n",
    "            ├── Homogenous/\n",
    "            ├── Aggregate/\n",
    "            └── Condensate/\n",
    "    \n",
    "    Args:\n",
    "        root_path (str): Path to the root directory containing category subfolders\n",
    "        \n",
    "    Returns:\n",
    "        list: List of dictionaries with keys: 'image', 'path', 'filename', 'category'\n",
    "    \"\"\"\n",
    "    subfolders = ['Homogenous', 'Aggregate', 'Condensate']\n",
    "    image_data = []\n",
    "    image_extensions = ['*.png', '*.jpg', '*.jpeg', '*.tif', '*.tiff']\n",
    "    \n",
    "    for subfolder in subfolders:\n",
    "        folder_path = os.path.join(root_path, subfolder)\n",
    "        \n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Warning: {folder_path} does not exist\")\n",
    "            continue\n",
    "            \n",
    "        for ext in image_extensions:\n",
    "            image_paths = glob(os.path.join(folder_path, '**', ext), recursive=True)\n",
    "            \n",
    "            for img_path in image_paths:\n",
    "                try:\n",
    "                    img = Image.open(img_path)\n",
    "                    img_array = np.array(img)\n",
    "                    \n",
    "                    image_info = {\n",
    "                        'image': img_array,\n",
    "                        'path': img_path,\n",
    "                        'filename': os.path.basename(img_path),\n",
    "                        'category': subfolder\n",
    "                    }\n",
    "                    image_data.append(image_info)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {img_path}: {str(e)}\")\n",
    "    \n",
    "    print(f\"Successfully loaded {len(image_data)} images\")\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c6f60b",
   "metadata": {},
   "source": [
    "## Threshold Detection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd4cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tail_kde(non_zero_pixels):\n",
    "    \"\"\"\n",
    "    Find histogram tail start using Kernel Density Estimation and derivative analysis.\n",
    "    \n",
    "    This method identifies inflection points in the pixel distribution where the\n",
    "    curve transitions from the main distribution to the tail (high-intensity regions).\n",
    "    \n",
    "    Args:\n",
    "        non_zero_pixels (array): Array of non-zero pixel values\n",
    "        \n",
    "    Returns:\n",
    "        float: The threshold value where the tail begins\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create KDE of the pixel distribution\n",
    "        kde = gaussian_kde(non_zero_pixels)\n",
    "        \n",
    "        # Evaluate KDE on a fine grid\n",
    "        x_grid = np.linspace(non_zero_pixels.min(), non_zero_pixels.max(), 1000)\n",
    "        pdf = kde(x_grid)\n",
    "        \n",
    "        # Calculate first derivative of the PDF\n",
    "        pdf_derivative = np.gradient(pdf, x_grid)\n",
    "        \n",
    "        # Find inflection points (where second derivative ≈ 0)\n",
    "        inflection_candidates = signal.find_peaks(-np.abs(np.gradient(pdf_derivative, x_grid)))[0]\n",
    "        \n",
    "        # Look for inflection point in the right half of distribution\n",
    "        # This identifies the transition to the tail\n",
    "        median_value = np.median(non_zero_pixels)\n",
    "        median_idx = np.argmin(np.abs(x_grid - median_value))\n",
    "        right_inflections = [i for i in inflection_candidates \n",
    "                            if i > median_idx and pdf[i] < 0.5 * pdf.max()]\n",
    "        \n",
    "        if right_inflections:\n",
    "            return x_grid[right_inflections[0]]\n",
    "        else:\n",
    "            # Fallback: use mean + 1.5 * std\n",
    "            return np.mean(non_zero_pixels) + 1.5 * np.std(non_zero_pixels)\n",
    "    except Exception as e:\n",
    "        print(f\"KDE tail detection failed: {e}\")\n",
    "        return np.mean(non_zero_pixels) + 1.5 * np.std(non_zero_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cfb1da",
   "metadata": {},
   "source": [
    "## Morphological Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4490d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_morphological_opening(binary_image, kernel_size=3):\n",
    "    \"\"\"\n",
    "    Apply morphological opening (erosion followed by dilation) to clean binary image.\n",
    "    \n",
    "    This operation:\n",
    "    1. Removes small noise particles (erosion step)\n",
    "    2. Restores shape of remaining objects (dilation step)\n",
    "    \n",
    "    Args:\n",
    "        binary_image (ndarray): Binary image (0 or 255 values)\n",
    "        kernel_size (int): Size of the square kernel for morphological operations\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: Cleaned binary image after opening\n",
    "    \"\"\"\n",
    "    # Ensure binary values (0 or 255)\n",
    "    if np.max(binary_image) == 1:\n",
    "        binary_image = binary_image * 255\n",
    "    \n",
    "    # Create square kernel\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    \n",
    "    # Apply erosion followed by dilation\n",
    "    eroded = cv2.erode(binary_image, kernel, iterations=1)\n",
    "    opened = cv2.dilate(eroded, kernel, iterations=1)\n",
    "    \n",
    "    return opened"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdd2a04",
   "metadata": {},
   "source": [
    "## Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6c3db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_processing_pipeline(image_data, n_samples=5, kernel_size=3):\n",
    "    \"\"\"\n",
    "    Display the complete processing pipeline for random image samples.\n",
    "    \n",
    "    Shows: Original → Histogram+Threshold → Binary → Morphologically Processed\n",
    "    \n",
    "    Args:\n",
    "        image_data (list): List of image dictionaries\n",
    "        n_samples (int): Number of random samples to display\n",
    "        kernel_size (int): Size of morphological kernel\n",
    "    \"\"\"\n",
    "    samples = random.sample(image_data, min(n_samples, len(image_data)))\n",
    "    \n",
    "    for img_info in samples:\n",
    "        img = img_info['image'].astype(np.float32)\n",
    "        \n",
    "        # Skip empty images\n",
    "        non_zero_pixels = img[img > 0]\n",
    "        if len(non_zero_pixels) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Calculate KDE threshold\n",
    "        threshold = find_tail_kde(non_zero_pixels)\n",
    "        \n",
    "        # Apply threshold\n",
    "        binary_img = (img > threshold).astype(np.uint8) * 255\n",
    "        \n",
    "        # Apply morphological opening\n",
    "        processed_img = apply_morphological_opening(binary_img, kernel_size)\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle(f\"{img_info['filename'][:20]}... ({img_info['category']})\", fontsize=16)\n",
    "        \n",
    "        # Original image\n",
    "        axes[0, 0].imshow(img, cmap='gray')\n",
    "        axes[0, 0].set_title(\"Original Image\")\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        # Histogram with threshold\n",
    "        axes[0, 1].hist(non_zero_pixels, bins=50, alpha=0.7, color='blue')\n",
    "        axes[0, 1].axvline(threshold, color='red', linestyle='--', \n",
    "                         label=f\"KDE threshold: {threshold:.1f}\")\n",
    "        axes[0, 1].set_title(\"Pixel Histogram\")\n",
    "        axes[0, 1].set_xlabel(\"Pixel Value\")\n",
    "        axes[0, 1].set_ylabel(\"Frequency\")\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Binary image\n",
    "        axes[1, 0].imshow(binary_img, cmap='gray')\n",
    "        axes[1, 0].set_title(f\"Binary (threshold={threshold:.1f})\")\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        # Morphologically processed\n",
    "        axes[1, 1].imshow(processed_img, cmap='gray')\n",
    "        axes[1, 1].set_title(f\"After Opening ({kernel_size}×{kernel_size} kernel)\")\n",
    "        axes[1, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605b6581",
   "metadata": {},
   "source": [
    "## Batch Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cd2de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_images(image_data, output_root_path, kernel_size=3):\n",
    "    \"\"\"\n",
    "    Process all images using KDE thresholding + morphological opening and save results.\n",
    "    \n",
    "    Args:\n",
    "        image_data (list): List of image dictionaries\n",
    "        output_root_path (str): Root directory for saving processed images\n",
    "        kernel_size (int): Size of morphological kernel\n",
    "    \"\"\"\n",
    "    # Create output directories\n",
    "    for category in ['Homogenous', 'Condensate', 'Aggregate']:\n",
    "        os.makedirs(os.path.join(output_root_path, category), exist_ok=True)\n",
    "    \n",
    "    category_counts = {'Homogenous': 0, 'Condensate': 0, 'Aggregate': 0}\n",
    "    \n",
    "    for i, img_info in enumerate(image_data):\n",
    "        category = img_info['category']\n",
    "        filename = img_info['filename']\n",
    "        target_path = os.path.join(output_root_path, category, filename)\n",
    "        \n",
    "        img = img_info['image'].astype(np.float32)\n",
    "        \n",
    "        # Extract non-zero pixels\n",
    "        non_zero_pixels = img[img > 0]\n",
    "        if len(non_zero_pixels) == 0:\n",
    "            print(f\"Skipping empty image: {filename}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Calculate KDE threshold\n",
    "            kde_threshold = find_tail_kde(non_zero_pixels)\n",
    "            \n",
    "            # Apply thresholding\n",
    "            binary_img = (img > kde_threshold).astype(np.uint8) * 255\n",
    "            \n",
    "            # Apply morphological opening\n",
    "            processed_img = apply_morphological_opening(binary_img, kernel_size)\n",
    "            \n",
    "            # Save processed image\n",
    "            Image.fromarray(processed_img).save(target_path)\n",
    "            category_counts[category] += 1\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Processed {i + 1}/{len(image_data)} images...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nProcessing complete!\")\n",
    "    print(f\"Total: {sum(category_counts.values())} images\")\n",
    "    for category, count in category_counts.items():\n",
    "        print(f\"{category}: {count} images\")\n",
    "    print(f\"Saved to: {output_root_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666d4174",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Load images from the dataset directory containing three categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure dataset path\n",
    "root_path = '/Users/klavs/Desktop/PhD/Tanu/image-thresholding/data/3'  # Update this path\n",
    "\n",
    "# Load images\n",
    "images = load_images_with_metadata(root_path)\n",
    "print(f\"Loaded {len(images)} total images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ece6d01",
   "metadata": {},
   "source": [
    "## Visualize Processing Pipeline\n",
    "\n",
    "Display the complete processing pipeline on random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1516af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display processing pipeline on 5 random samples\n",
    "display_processing_pipeline(images, n_samples=5, kernel_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4cf07a",
   "metadata": {},
   "source": [
    "## Batch Process All Images\n",
    "\n",
    "Apply KDE thresholding + morphological opening to all images and save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc1bdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure output path\n",
    "output_path = '/Users/klavs/Desktop/PhD/Tanu/image-thresholding/data/3'  # Update this path\n",
    "\n",
    "# Process and save all images\n",
    "process_and_save_images(images, output_path, kernel_size=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "droplet_classification_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
